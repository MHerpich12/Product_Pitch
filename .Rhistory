training1 <- subset(segmentationOriginal,segmentationOriginal$Case=="Train")
testing <- subset(segmentationOriginal,segmentationOriginal$Case=="Test")
unique(training1$Case)
head(training1,n=5)
head(testing1,n=5)
testing1 <- subset(segmentationOriginal,segmentationOriginal$Case=="Test")
head(testing1,n=5)
set.seed(125)
modFit1 <- train(Class~.,method="rpart",data=training1)
install.packages("rattle")
fancyRpartPlot(modFit1$finalModel)
library(rattle)
fancyRpartPlot(modFit1$finalModel)
load("olive.rda")
newolive <- olive[,-1]
head(newolive,n=5)
tail(newolive,n=5)
modFit3 <- train(Area~.,method="rpart",data=newolive)
newdata = as.data.frame(t(colMeans(olive)))
newdata = as.data.frame(t(colMeans(newolive)))
predict(modFit3,newdata)
set.seed(125)
modFit3 <- train(Area~.,method="rpart",data=newolive)
predict(modFit3,newdata)
install.package("pgmm")
install.packages("pgmm")
library(pgmm)
data(olive)
newolive <- olive[,-1]
modFit3 <- train(Area~.,method="rpart",data=newolive)
predict(modFit3,newdata)
install.packages("tree")
?tree
library(tree)
?tree
out3 <- tree(Area~.,data=newolive)
plot(out3)
?tree
out3
newdata = as.data.frame(t(colMeans(olive)))
predict(out3,newdata)
source("MachineLearning1.R")
head(InMatrix,n=5)
?createDataPartition
source("MachineLearning1.R")
dim(training); dim(validation)
dim(training)
folds <- createFolds(y=InMatrix$classe,k=10,list=TRUE)
head(folds,n=5)
dim(folds)
head(folds[1],n=5)
sapply(folds[[1]],length)
sapply(folds[1],length)
folds1 <- createFolds(y=InMatrix$classe,k=10,list=TRUE,returnTrain=TRUE)
sapply(folds1[1],length)
sapply(folds1,length)
folds2 <- createFolds(y=InMatrix$classe,k=10,list=TRUE,returnTrain=FALSE)
sapply(folds2,length)
?read.csv
str(InMatrix$classe)
source("MachineLearning1.R")
head(InMatrix,n=5)
sum(is.na(InMatrix$var_yaw_dumbell))
sum(is.na(InMatrix$var_yaw_dumbbell))
sum(is.na(InMatrix$classe))
source("MachineLearning1.R")
source("MachineLearning1.R")
head(NAvec,n=10)
head(NAvec,n=30)
sum(is.na(testing[,130]))
head(testing[,1],n=5)
head(testing[,1],n=12)
head(testing[,12],n=5)
sum(is.na(testing[,12]))
NAvec[12]
length(NAvec)
length(testing[,12])
source("MachineLearning1.R")
head(NAvec,n=15)
sum(is.na(testing[,5]))
sum(is.na(testing[,10]))
sum(is.na(testing[,115]))
sum(is.na(testing[,15]))
length(names(testing))
source("MachineLearning1.R")
head(NAvec,n=15)
source("MachineLearning1.R")
colhead
source("MachineLearning1.R")
length(names(training))
source("MachineLearning1.R")
source("MachineLearning1.R")
length(names(testing))
head(testing,n=5)
head(training,n=5)
length(names(training))
?preProcess
length(names(training))
training[,-53]
head(training[,-53],n=5)
source("MachineLearning1.R")
length(names(training))
length(names(trainProc))
head(testing[,53])
source("MachineLearning1.R")
length(names(testing))
length(names(testProc))
head(trainProc,n=5)
length(trainProc$PC1)
source("MachineLearning1.R")
head(finaltrain,n=5)
head(training$classe,n=5)
?train
source("MachineLearning1.R")
finaltrain$training$classe
names(finaltrain)
source("MachineLearning1.R")
head(finaltrain,n=5)
source("MachineLearning1.R")
?randomForest
library(caret)
?randomForest
library(randomForest)
?randomForest
source("MachineLearning1.R")
source("MachineLearning1.R")
source("MachineLearning1.R")
source("MachineLearning1.R")
head(ftrain1,n=5)
source("MachineLearning1.R")
head(ftrain1$classe)
str(ftrain1$classe)
tail(ftrain1,n=5)
source("MachineLearning1.R")
install.package("gbm")
install.packages("gbm")
source("MachineLearning1.R")
source("MachineLearning1.R")
head(ftrain1,n=5)
length(ftrain1$PC1)
length(ftrain1$classe)
source("MachineLearning1.R")
source("MachineLearning1.R")
length(ftrain1sub$classe)
source("MachineLearning1.R")
source("MachineLearning1.R")
confusionMatrix(fvalid1$classe,predict(Model,fvalid1[,-length(names(fvalid1))]))
source("MachineLearning1.R")
source("MachineLearning1.R")
source("MachineLearning1.R")
source("MachineLearning1.R")
head(testProc,n=5)
predict(Model,fvalid1[,-length(names(fvalid1))])
vec1 <- as.vector(predict(Model,fvalid1[,-length(names(fvalid1))]))
head(vec1,n=10)
tail(vec1,n=10)
source("MachineLearning1.R")
Outcome
length(Outcome)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(Outcome)
?ConfusionMatrix
?confusionMatrix
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train,n=5)
training <- vowel.train
training$y <- factor(training$y)
testing <- vowel.test
testing$y <- factor(testing$y)
set.seed(33833)
mod1 <- train(y~.,data=training,type="rf")
library(caret)
mod1 <- train(y~.,data=training,type="rf")
mod2 <- train(y~.,data=training,type="gbm")
confusionMatrix(testing$y,predict(mod1,testing[,-1]))
confusionMatrix(predict(mod1,testing[,-1]),testing$y)
head(testing,n=5)
head(testing[,-1],n=5)
head(training,n=5)
head(vowel.train,n=5)
tail(vowel.train,n=5)
confusionMatrix(predict(mod2,testing[,-1]),testing$y)
str(vowel.train)
str(training)
str(testing)
mod1 <- train(y~.,data=training,method="rf",prox=TRUE)
mod2 <- train(y~.,data=training,method="gbm",prox=TRUE)
mod2 <- train(y~.,data=training,method="gbm")
confusionMatrix(predict(mod1,testing[,-1]),testing$y)
confusionMatrix(predict(mod2,testing[,-1]),testing$y)
set.seed(33833)
mod1 <- train(y~.,data=training,method="rf",prox=TRUE)
set.seed(33833)
mod2 <- train(y~.,data=training,method="gbm",verbose=FALSE)
confusionMatrix(predict(mod1,testing[,-1]),testing$y)
confusionMatrix(predict(mod2,testing[,-1]),testing$y)
output <- data.frame(predict(mod1,testing[,-1]),predict(mod2,testing[,-1]),testing$y)
names(output) <- c("first","second","final")
out1 <- subset(output,output$first==output$second)
length(out1$first)
count(out1$second==out1$final)
205/318
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData=data.frame(diagnosis,predictors)
intrain <- createDataPartition(adData$diagnosis,p=3/4)[[1]]
training <- adData[intrain,]
testing <- adData[-intrain,]
set.seed(62433)
mod1 <- train(diagnosis~.,data=training,method="rf",prox=TRUE)
set.seed(62433)
mod2 <- train(diagnosis~.,data=training,method="gbm",verbose=FALSE)
set.seed(62433)
mod3 <- train(diagnosis~.,data=training,method="lda")
head(testing,n=5)
mat1 <- confsuionMatrix(predict(mod1,testing[,-1]),testing$diagnosis)
mat1 <- confusionMatrix(predict(mod1,testing[,-1]),testing$diagnosis)
mat2 <- confusionMatrix(predict(mod2,testing[,-1]),testing$diagnosis)
mat3 <- confusionMatrix(predict(mod3,testing[,-1]),testing$diagnosis)
frame1 <- data.frame(testing$diagnosis,predict(mod1,testing[,-1]),predict(mod2,testing[,-1]),predict(mod3,testing[,-1]))
names(frame1) <- c("output","mod1","mod2","mod3")
mod4 <- train(output~.,data=frame1,method="rf",prox=TRUE)
head(frame1,n=5)
frame1 <- data.frame(training$diagnosis,predict(mod1,testing[,-1]),predict(mod2,testing[,-1]),predict(mod3,testing[,-1]))
frame1 <- data.frame(training$diagnosis,predict(mod1,training[,-1]),predict(mod2,training[,-1]),predict(mod3,training[,-1]))
names(frame1) <- c("output","mod1","mod2","mod3")
mod4 <- train(output~.,data=frame1,method="rf",prox=TRUE)
frame2 <- data.frame(testing$diagnosis,predict(mod1,testing[,-1]),predict(mod2,testing[,-1]),predict(mod3,testing[,-1]))
names(frame2) <- c("output","mod1","mod2","mod3")
mat4 <- confusionMatrix(predict(mod4,frame2[,-1]),testing$diagnosis)
mat1
mat1$Accuracy
mat1$acc
mat1$ac
mat1
mat2
mat3
mat4
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,p=3/4)[[1]]
training <- concrete[inTrain,]
testing <- concrete[-inTrain,]
set.seed(233)
mod1 <- train(CompressiveStrength~.,data=training,method="lasso")
mod1 <- train(CompressiveStrength~.,data=training,method="lasso")
?plot.enet
mod1
mod1$coeff
mod1$coef
?plot.enet
?enet
head(training,n=5)
head(training[,-8]n=5)
head(training[,-8],n=5)
head(training[,-7],n=5)
head(training,n=5)
head(training[,8]n=5)
head(training[,8],n=5)
head(training[,-8],n=5)
mod2 <- enet(training[,-8],training[,8],0)
input <- training[,-8]
names(input)
head(input[,8],n=5)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
head(training,n=5)
head(training[,1:7],n=5)
set.seed(233)
object1 <- enet(training[,1:7],training$CompressiveStrength,lambda=0)
object1 <- enet(training[[1:7]],training$CompressiveStrength,lambda=0)
head(training[[1:7]])
object1 <- enet(training$Cement,training$CompressiveStrength,lambda=0)
input <- training[,1:7]
head(input,n=5)
object1 <- enet(input,training$CompressiveStrength,lambda=0)
str(training)
training$age <- as.numeric(training$age)
str(training)
str(training$age)
training$Age <- as.numeric(training$Age)
str(training)
object1 <- enet(training[,1:7],training[,8],lambda=0)
input <- as.matrix(training[,1:7])
head(input)
output <- as.numeric(training$CompressiveStrength)
object1 <- enet(input,output,lambda=0)
plot.enet(object1)
plot.enet(penalty,object1)
?plot.enet
plot(object1,xvar="penalty")
library(lubridate)
data <- read.csv("~/Desktop/gaData.csv")
data <- read.csv("C:\Users\mcherpich\Desktop\gaData.csv")
data <- read.csv("C:/Users/mcherpich/Desktop/gaData.csv")
training = data[year(dat$date) < 2012,]
training = data[year(data$date) < 2012,]
testing = data[(year(data$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
dat <- read.csv("C:/Users/mcherpich/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
head(dat,n=5)
str(dat$date)
dat <- read.csv("C:/Users/mcherpich/Desktop/gaData.csv",as.is=TRUE)
training = dat[year(dat$date) < 2012,]
str(dat)
dat$date <- as.Date(dat$date,"%m/%d/%y")
str(dat)
head(dat,n=5)
dat <- read.csv("C:/Users/mcherpich/Desktop/gaData.csv",as.is=TRUE)
head(dat,n=5)
dat$date <- as.Date(dat$date)
head(dat,n=5)
head(dat,n=15)
dat <- read.csv("C:/Users/mcherpich/Desktop/gaData.csv",as.is=TRUE)
head(dat,n=15)
training <- dat[year(dat$date<2012),]
?strptime
dat <- read.csv("C:/Users/mcherpich/Desktop/gaData.csv",as.is=TRUE)
head(dat,n=15)
dat$date <- as.Date(dat$date,"%m%d%y")
head(dat,n=15)
dat <- read.csv("C:/Users/mcherpich/Desktop/gaData.csv",as.is=TRUE)
head(dat,n=15)
dat$date <- as.Date(dat$date, "%m/%d/%y")
head(dat,n=15)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
install.packages("forecast")
library(forecast)
?bats
head(training,n=5)
tfit <- bats(training$visitsTumblr)
plot(forecast(tfit))
out <- forecast(tfit)
head(out,n=5)
mat <- out$upper
tail(mat,n=10)
?bats
length(testing$date)
model <- forecast(bats(training$visitsTumblr),235,level=c(95),fan=FALSE)
plot(model)
final <- data.frame(model$lower,model$upper,testing$visitsTumblr)
head(final,n=15)
names(final) <- c("lower","upper","actual")
final2 <- subset(final, final$actual <= final$upper & final$actual >= final$lower)
length(final$actual)
length(final2$actual)
226/235
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(235)
set.seed(325)
install.packages("e1071")
set.seed(3523)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
?svm
model <- svm(CompressiveStrength~.,data=training)
predict(model,testing[,-8])
head(training,n=5)
head(testing,n=5)
model <- svm(CompressiveStrength~.,data=training)
predict(model,testing)
output <- predict(model,testing)
head(output,n=5)
confusionMatrix(testing$CompressiveStrength,predict(model,training[,-8]))
head(training[,-8],n=5)
confusionMatrix(testing$CompressiveStrength,predict(model,training[,-9]))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain <- createDataPartition(concrete$compressiveStrength,p=3/4)[[1]]
inTrain <- createDataPartition(concrete$CompressiveStrength,p=3/4)[[1]]
training <- concrete[inTrain,]
testing <- concrete[-inTrain,]
set.seed(325)
model <- svm(CompressiveStrength~.,data=training)
confusionMatrix(testing$compressiveStrength,predict(model,testing[,-9]))
head(testing,n=5)
str(training)
str(testing)
output <- testing[,-9]
str(output)
n <- predict(model,output)
mat <- confusionMatrix(testing$CompressiveStrength,predict(model,output))
x <0 subset(training, select= -CompressiveStrength)
x <- subset(training, select= -CompressiveStrength)
y <- training$CompressiveStrength
model <- svm(x,y)
mat <- confusionMatrix(testing$CompressiveStrength,predict(model,output))
model <- train(CompressiveStrength~.,data=training,method="glm")
confusionMatrix(testing$CompressiveStrength,predict(model,testing[,-9]))
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,p=3/4)[[1]]
training <- concrete[inTrain,]
testing <- concrete[-inTrain,]
set.seed(325)
model <- train(CompressiveStrength~.,data=training,method="glm")
output <- subset(testing, select=-CompressiveStrength)
confusionMatrix(testing$CompressiveStrength,predict(model,output))
output <- predict(model,testing)
output <- predict(model,testing[,-9])
str(output)
len(output)
length(output)
length(testing$compressiveStrength)
length(testing$CompressiveStrength)
model <- svm(CompressiveStrength~.,data=training)
output <- predict(model,testing)
output <- predict(model,testing[,1:8])
str(output)
model <- svm(training[,1:8],training[,9])
output <- predict(model,testing[,1:8])
str(output)
?rmse
install.packages("metrics")
library(metrics)
?rmse
install.packages("Metrics")
library(Metrics)
?rsme
?rmse
rmse(testing$compressiveStrength,output)
str(output)
output <- as.numeric(as.character(output))
str(output)
rmse(testing$compressiveStrength,output)
head(testing$CompressiveStrength)
length(testing$CompressiveStrength)
length(output)
rmse(testing$CompressiveStrength,output)
install.packages("shiny")
install.packages("googleVis")
suppressPackageStartupMessages(library(googleVis))
M <- gvisMotionChart(Fruits, "Fruit","Year",options=list(width=600,height=400))
print(M,"chart")
plot(M)
install.packages("devtools")
install.packages("plotly")
library(plotly)
library("devtools")
install_github("ropensci/plotly")
library(plotly)
library(manipulate)
myplot <- function(s) { }
myplot <- function(s) { plot(cars$dist - mean(cars$dist),cars$speed - mean(cars$speed)) abline(0,s)}
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s),s=slider(0,2,step=0.1))
library(rcharts)
install.packages("rcharts")
install.packages("rCharts")
require(devtools)
install_github('rCharts', 'ramnathv')
require(rCharts)
library(datasets)
data(airquality)
dTable(airquality,sPaginationType="full_numbers")
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
install.packages("knitr")
getwd()
setwd("~/DataProducts")
require("shiny")
runApp()
setwd("C:/Users/mcherpich/Documents/DataProducts/Product_Pitch")
library("slidify")
slidify("index.Rmd")
library(knitr)
browseURL("index.HTML")
